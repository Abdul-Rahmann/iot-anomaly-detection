{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T01:52:02.506107Z",
     "start_time": "2025-03-17T01:52:02.491160Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "592485c144773aae",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T01:52:02.549959Z",
     "start_time": "2025-03-17T01:52:02.512555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_normal = pd.read_parquet(\"../data/processed/df_normal.parquet\")\n",
    "df_anomaly = pd.read_parquet(\"../data/processed/df_anomaly.parquet\")\n",
    "\n",
    "print(f\"Normal data shape: {df_normal.shape}\")\n",
    "print(f\"Anomaly data shape: {df_anomaly.shape}\")"
   ],
   "id": "1a660134c41526b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal data shape: (316443, 13)\n",
      "Anomaly data shape: (127391, 13)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Isolation Forest",
   "id": "a78365ccc27034a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T01:52:05.285735Z",
     "start_time": "2025-03-17T01:52:02.563111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = IsolationForest(contamination=0.05, random_state=42)\n",
    "model.fit(df_normal)\n",
    "\n",
    "y_pred_normal = model.predict(df_normal)\n",
    "y_pred_anomaly = model.predict(df_anomaly)\n",
    "\n",
    "y_true = [1] * len(y_pred_normal) + [-1] * len(y_pred_anomaly)\n",
    "y_pred = list(y_pred_normal) + list(y_pred_anomaly)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "id": "7e02ea7beeebe64a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.29      0.05      0.09    127391\n",
      "           1       0.71      0.95      0.81    316443\n",
      "\n",
      "    accuracy                           0.69    443834\n",
      "   macro avg       0.50      0.50      0.45    443834\n",
      "weighted avg       0.59      0.69      0.61    443834\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T01:52:10.554394Z",
     "start_time": "2025-03-17T01:52:05.294641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tuning IsolationForest for better performance\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Tune Isolation Forest\n",
    "model = IsolationForest(\n",
    "    n_estimators=200,        # Increase trees for better anomaly detection\n",
    "    max_samples=256,         # Control the number of samples per tree\n",
    "    contamination=0.1,       # Adjust based on expected anomaly proportion\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(df_normal)\n",
    "\n",
    "y_pred_normal = model.predict(df_normal)\n",
    "y_pred_anomaly = model.predict(df_anomaly)\n",
    "\n",
    "y_true = [1] * len(y_pred_normal) + [-1] * len(y_pred_anomaly)\n",
    "y_pred = list(y_pred_normal) + list(y_pred_anomaly)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "id": "bb0a6ae8b4f01998",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.29      0.10      0.15    127391\n",
      "           1       0.71      0.90      0.80    316443\n",
      "\n",
      "    accuracy                           0.67    443834\n",
      "   macro avg       0.50      0.50      0.47    443834\n",
      "weighted avg       0.59      0.67      0.61    443834\n",
      "\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### SVM: OnceClassSVM",
   "id": "47d1d265a24cf044"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T01:52:18.183916Z",
     "start_time": "2025-03-17T01:52:10.562899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "n_data =  5000\n",
    "model = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=\"auto\")\n",
    "model.fit(df_normal[:n_data])\n",
    "\n",
    "y_pred_normal = model.predict(df_normal)\n",
    "y_pred_anomaly = model.predict(df_anomaly)\n",
    "\n",
    "y_true = [1] * len(y_pred_normal) + [-1] * len(y_pred_anomaly)\n",
    "y_pred = list(y_pred_normal) + list(y_pred_anomaly)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "id": "eeb7ee63a778f81a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.29      0.11      0.16    127391\n",
      "           1       0.71      0.89      0.79    316443\n",
      "\n",
      "    accuracy                           0.67    443834\n",
      "   macro avg       0.50      0.50      0.48    443834\n",
      "weighted avg       0.59      0.67      0.61    443834\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T01:52:18.223466Z",
     "start_time": "2025-03-17T01:52:18.192510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Apply feature scaling\n",
    "scaler = StandardScaler()\n",
    "df_normal_scaled = scaler.fit_transform(df_normal)\n",
    "df_anomaly_scaled = scaler.transform(df_anomaly)"
   ],
   "id": "f297f30c3323c717",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T01:52:23.057971Z",
     "start_time": "2025-03-17T01:52:18.232220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# OneClassSVM on scaled data\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "n_data =  3000\n",
    "\n",
    "model = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=\"auto\")\n",
    "model.fit(df_normal_scaled[:n_data])\n",
    "\n",
    "y_pred_normal = model.predict(df_normal_scaled)\n",
    "y_pred_anomaly = model.predict(df_anomaly_scaled)\n",
    "\n",
    "y_true = [1] * len(y_pred_normal) + [-1] * len(y_pred_anomaly)\n",
    "y_pred = list(y_pred_normal) + list(y_pred_anomaly)\n",
    "\n",
    "# Evaluate model\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "id": "f0e9854cfa02af20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.29      0.12      0.17    127391\n",
      "           1       0.71      0.88      0.79    316443\n",
      "\n",
      "    accuracy                           0.66    443834\n",
      "   macro avg       0.50      0.50      0.48    443834\n",
      "weighted avg       0.59      0.66      0.61    443834\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T01:52:27.933301Z",
     "start_time": "2025-03-17T01:52:23.120669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tuned OneClassSVM\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "n_data =  30000\n",
    "\n",
    "model = OneClassSVM(nu=0.05, kernel=\"rbf\", gamma=0.001)\n",
    "model.fit(df_normal[:n_data])\n",
    "\n",
    "\n",
    "y_pred_normal = model.predict(df_normal[:n_data])\n",
    "y_pred_anomaly = model.predict(df_anomaly[:n_data])\n",
    "\n",
    "y_true = [1] * len(y_pred_normal) + [-1] * len(y_pred_anomaly)\n",
    "y_pred = list(y_pred_normal) + list(y_pred_anomaly)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "id": "8dbb3a7d1f024997",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.48      0.05      0.08     30000\n",
      "           1       0.50      0.95      0.65     30000\n",
      "\n",
      "    accuracy                           0.50     60000\n",
      "   macro avg       0.49      0.50      0.37     60000\n",
      "weighted avg       0.49      0.50      0.37     60000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Gaussian Mixture Model (GMM)",
   "id": "c1dac5dafb858d48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T02:14:41.589288Z",
     "start_time": "2025-03-17T02:14:38.435432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Fit GMM on normal data\n",
    "model = GaussianMixture(n_components=2, covariance_type=\"full\", random_state=42)\n",
    "model.fit(df_normal)\n",
    "\n",
    "# Compute log-likelihood scores for normal and anomalous data\n",
    "normal_scores = model.score_samples(df_normal)\n",
    "anomaly_scores = model.score_samples(df_anomaly)\n",
    "\n",
    "# Set threshold based on normal score distribution\n",
    "threshold_percentile = 5  # Adjust as needed\n",
    "threshold = np.percentile(normal_scores, threshold_percentile)\n",
    "\n",
    "# Classify data based on the threshold (anomalies <- below threshold)\n",
    "y_pred_normal = (normal_scores < threshold).astype(int)  # 1 if anomaly, 0 if normal\n",
    "y_pred_anomaly = (anomaly_scores < threshold).astype(int)\n",
    "\n",
    "# Combine predictions\n",
    "y_pred = np.concatenate([y_pred_normal, y_pred_anomaly])  # 1 (anomaly), 0 (normal)\n",
    "y_pred = np.where(y_pred == 1, -1, 1)  # Convert to -1 (anomaly), 1 (normal)\n",
    "\n",
    "# Create true labels\n",
    "y_true = np.concatenate([np.ones(len(df_normal)), -1 * np.ones(len(df_anomaly))])\n",
    "\n",
    "# Ensure labels align correctly\n",
    "print(\"True labels:\", np.unique(y_true, return_counts=True))\n",
    "print(\"Predicted labels:\", np.unique(y_pred, return_counts=True))\n",
    "\n",
    "# Evaluate performance\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n"
   ],
   "id": "889bf01bc72eb605",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels: (array([-1.,  1.]), array([127391, 316443]))\n",
      "Predicted labels: (array([-1,  1]), array([ 22635, 421199]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.30      0.05      0.09    127391\n",
      "         1.0       0.71      0.95      0.82    316443\n",
      "\n",
      "    accuracy                           0.69    443834\n",
      "   macro avg       0.51      0.50      0.45    443834\n",
      "weighted avg       0.60      0.69      0.61    443834\n",
      "\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T02:14:28.567016Z",
     "start_time": "2025-03-17T02:14:24.792204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.spatial.distance import mahalanobis\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Compute mean and covariance of normal data\n",
    "cov_matrix = np.cov(df_normal.T)\n",
    "inv_cov = np.linalg.inv(cov_matrix)\n",
    "mean_normal = df_normal.mean(axis=0)\n",
    "\n",
    "# Compute Mahalanobis distance for normal and anomalous data\n",
    "normal_distances = [mahalanobis(x, mean_normal, inv_cov) for x in df_normal.values]\n",
    "anomaly_distances = [mahalanobis(x, mean_normal, inv_cov) for x in df_anomaly.values]\n",
    "\n",
    "# Set threshold based on normal data (e.g., 95th percentile)\n",
    "threshold = np.percentile(normal_distances, 95)\n",
    "\n",
    "# Classify both normal and anomaly data points\n",
    "y_pred_normal = np.where(np.array(normal_distances) > threshold, -1, 1)  # Normal points\n",
    "y_pred_anomaly = np.where(np.array(anomaly_distances) > threshold, -1, 1)  # Anomalies\n",
    "\n",
    "# Combine predictions and true labels\n",
    "y_pred = np.concatenate([y_pred_normal, y_pred_anomaly])  # Merge predictions\n",
    "y_true = np.concatenate(\n",
    "    [np.ones(len(y_pred_normal)), -1 * np.ones(len(y_pred_anomaly))])  # 1 for normal, -1 for anomalies\n",
    "\n",
    "# Evaluate model\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n"
   ],
   "id": "81bd128565a89a20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.30      0.05      0.09    127391\n",
      "         1.0       0.71      0.95      0.82    316443\n",
      "\n",
      "    accuracy                           0.69    443834\n",
      "   macro avg       0.51      0.50      0.45    443834\n",
      "weighted avg       0.60      0.69      0.61    443834\n",
      "\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b85c1677ad54c97d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
